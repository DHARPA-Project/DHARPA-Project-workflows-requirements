{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+","tags":false},"docs":[{"location":"","text":"<p>This repository aims at documenting the collection of workflow examples in the context of the DHARPA project, in order to identify data patterns and features for implementation.</p> <p>At the moment, additional relevant workflow examples can be added by simply creating a new file using the \"blank-workflow.md\" template.</p> <p>Each example contains the following sections: * Data: description of the data used in the example * Workflow: information about the goals of the workflow * Steps: the different steps considered * Implementation: this section enables to inform about implementation status of features selected for implementation, and links to the relevant DHARPA repo.</p>","title":"Home"},{"location":"blank-workflow/","text":"","title":"Name of the example"},{"location":"blank-workflow/#1-data","text":"DescriptionNumber of filesFiles typeFiles aliasColumns   <p>Description of the data used</p>     <p>Files alias is to simplify references to datasets for present doc</p>","title":"1. Data"},{"location":"blank-workflow/#table-namedata-alias","text":"","title":"Table name/Data alias:"},{"location":"blank-workflow/#all","text":"<p>List of all columns</p>","title":"All"},{"location":"blank-workflow/#mandatory","text":"<p>List of mandatory columns (without these columns, module won't work)</p>","title":"Mandatory"},{"location":"blank-workflow/#standardised","text":"<p>List of standardised column names</p>","title":"Standardised"},{"location":"blank-workflow/#2-workflow","text":"Workflow scopeExamples of research questionsWorkflow text summaryWorkflow inputWorkflow output   <p>Description of what the workflow achieves</p> <p>Workflow curated or created by/from: DH Researcher/Developer/Training/Internet</p> <p>DH related example? yes/no</p>   <p>Please list a few examples of research questions that this workflow could help with</p>   <p>Description of the workflow steps in a text form</p>   <p>Description of data that users need to start the workflow</p>   <p>Description of the expected data output for the workflow</p>","title":"2. Workflow"},{"location":"blank-workflow/#3-steps-considered","text":"","title":"3. Steps considered"},{"location":"blank-workflow/#step-number","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources        Name Type               Name Type            <p>Research (e.g. are there examples of specific research questions for this step, or any research considerations to take into account) and/or UI considerations (e.g. will users need to make a critical decision at this step, which would need to be emphasized in the UI) Performance considerations (UI or back-end)</p>   <p>For example, links to UI or visualzation examples</p>","title":"Step number"},{"location":"blank-workflow/#4-implementation","text":"<p>In case of implementation, this section enables to indicate features concerned and link to the relevant DHARPA's Github repo</p>","title":"4. Implementation"},{"location":"lda-gensim/","text":"","title":"Topic modeling LDA"},{"location":"lda-gensim/#1-data","text":"DescriptionNumber of filesFiles typeFiles aliasColumns   <p>Description of the data used folder containing list of text files, file names contain metadata</p>   <p>Number of files can vary, in the current example approximately 7000 text files</p>   <p>txt</p>   <p>n/a as large number of files</p>","title":"1. Data"},{"location":"lda-gensim/#table-namedata-alias","text":"","title":"Table name/Data alias:"},{"location":"lda-gensim/#all","text":"<p>List of all columns</p>         files_list   files_names","title":"All"},{"location":"lda-gensim/#mandatory","text":"<p>To be determined with pre-processing strategy. In this case, I will assume that the initial tabular data contains a files_list and file_names columns.</p>","title":"Mandatory"},{"location":"lda-gensim/#standardised","text":"<p>standardised names to be determined</p>","title":"Standardised"},{"location":"lda-gensim/#2-workflow","text":"Workflow scopeExamples of research questionsWorkflow text summaryWorkflow inputWorkflow output   <p>Performing text analysis tasks on a corpus of documents</p> <p>Workflow curated or created by/from: DH Researcher</p> <p>DH related example? yes</p>   <p>Please list a few examples of research questions that this workflow could help with</p>   <p>Description of the workflow steps in a text form</p>   <p>Folder containing text files</p>   <p>Description of the expected data output for the workflow</p>","title":"2. Workflow"},{"location":"lda-gensim/#3-steps-considered","text":"","title":"3. Steps considered"},{"location":"lda-gensim/#step-1","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Transform data sources into tabular data/exploitable format</p>       Name Type     files collection corpus         Name Type     corpus_table table(files_name,files_content?(see note))      <p>For the next step, files content may not be necessary yet. It may only be necessary to add the file content after filtering the corpus by date.</p>","title":"Step 1"},{"location":"lda-gensim/#step-2","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Get metadata</p>   <p>Get metadata contained in the files name</p>      Name Type     files_name string   publications dict or list of strings collected as user input         Name Type     files_name string   date string   publication_name string      <p>Depending on the metadata to extract, users may need to input the publication names that match the reference provided in file name. Previews may be needed at every step. This step may not be applicable to all types of corpus, e.g. with social media data.</p>","title":"Step 2"},{"location":"lda-gensim/#step-3","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Filtering corpus by date</p>   <p>Filter corpus by date and visualise distribution</p>      Name Type     files_name string   date string   publication_name string   start_date string or date   end_date string or date         Name Type     files_name string   date string   publication_name string      <p>Visualization would assist users filtering their data, they would see the modification on viz before validating the inputs.</p>   <p>Visualization: https://observablehq.com/@dharpa-project/timestamped-corpus</p>","title":"Step 3"},{"location":"lda-gensim/#step-4","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Add text content in dataset</p>   <p>Retrieve .txt files content and add to dataset, if not done at step 1</p>      Name Type     files_name string   date string   publication_name string         Name Type     files_name string   date string   publication_name string   document string      <p>Not sure if the text would be best added here or at the first step.</p>","title":"Step 4"},{"location":"lda-gensim/#step-5","text":"Step nameDescriptionInputsOutputs   <p>Removing stop words, punctuation, short words</p>   <p>Perform operations on the text to focus on the tokens that bring an interpretative value</p>      Name Type     files_name string   date string   publication_name string   stop_words_list array or csv   text_processing_options array or object   document string         Name Type     files_name string   date string   publication_name string   document string","title":"Step 5"},{"location":"lda-gensim/#step-6","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Lemmatize</p>   <p>Lemmatize corpus</p>      Name Type     files_name string   date string   publication_name string   language string   document string         Name Type     files_name string   date string   publication_name string   document string","title":"Step 6"},{"location":"lda-gensim/#step-7","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>LDA</p>   <p>Run LDA</p>      Name Type     files_name string   date string   publication_name string   document string   filter_extremes array or boolean   hyper_parameters array or object   number_of_topics integer or boolean         Name Type     models array or object   scores array or object      <p>This step needs to be refined while iterating with code/ui</p>","title":"Step 7"},{"location":"lda-gensim/#step-8","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Number of topics</p>   <p>Decide on number of topics</p>      Name Type     models array of arrays or object   scores array or object         Name Type     model array   score float","title":"Step 8"},{"location":"lda-gensim/#step-9","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Number of topics</p>   <p>Decide on number of topics</p>      Name Type     models array of arrays or object   scores array or object         Name Type     model array   score float","title":"Step 9"},{"location":"lda-gensim/#step-10","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Number of topics</p>   <p>Decide on number of topics</p>      Name Type     models array of arrays or object   scores array or object         Name Type     model array   score float","title":"Step 10"},{"location":"lda-gensim/#step-11","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Topic visualisation</p>   <p>Visualize topics with pyLDAvis python package</p>      Name Type               Name Type            <p>Inputs and outputs to be determined</p>","title":"Step 11"},{"location":"lda-gensim/#step-12","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Topics naming and categorisation</p>       Name Type               Name Type            <p>Inputs and outputs to be determined</p>","title":"Step 12"},{"location":"lda-gensim/#step-13","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Distribution computations</p>   <p>Compute ditributions (per topic and per document, per topic for the whole corpus, per publication)</p>      Name Type     model object or string (to be verified)   corpus document list with content         Name Type     distribution_per_topic_per_doc table   distribution_per_topic_whole_corpus table   distribution_per_publication table","title":"Step 13"},{"location":"lda-gensim/#step-14","text":"Step nameDescriptionInputsOutputsNotesLinks to useful ressources   <p>Distribution per topic for the whole corpus</p>       Name Type     corpus document list with content   distribution_computations table         Name Type     distribution_computations table","title":"Step 14"},{"location":"lda-gensim/#4-implementation","text":"<p>In case of implementation, this section enables to indicate features concerned and link to the relevant DHARPA's Github repo</p>","title":"4. Implementation"},{"location":"na-bipartite/","text":"","title":"Bipartite graph"},{"location":"na-bipartite/#1-data","text":"DescriptionNumber of filesFiles typeFiles aliasColumns   <p>Network data concerning soldiers and the units they served in</p>   <p>3</p>   <p>csv</p>   <p>Files alias is to simplify references to datasets for present doc</p> <ul> <li>nodes1</li> <li>nodes2</li> <li>edges</li> </ul>","title":"1. Data"},{"location":"na-bipartite/#table-nodes1","text":"","title":"Table \"nodes1\""},{"location":"na-bipartite/#all","text":"SoldierId   entrynoout   Branch   entmeth2   outmeth3   ENTlat   ENTlong   YOB   isknowfarming","title":"All"},{"location":"na-bipartite/#mandatory","text":"<p>Id (here SoldierId)</p>","title":"Mandatory"},{"location":"na-bipartite/#standardised","text":"<p>Id</p>","title":"Standardised"},{"location":"na-bipartite/#table-nodes2","text":"","title":"Table \"nodes2\""},{"location":"na-bipartite/#all_1","text":"UnitId   unitname","title":"All"},{"location":"na-bipartite/#mandatory_1","text":"<p>Id (here UnitId)</p>","title":"Mandatory"},{"location":"na-bipartite/#standardised_1","text":"<p>Id</p>","title":"Standardised"},{"location":"na-bipartite/#table-edges","text":"","title":"Table \"edges\""},{"location":"na-bipartite/#all_2","text":"Source   Target   unitduration","title":"All"},{"location":"na-bipartite/#mandatory_2","text":"<p>Source, Target</p>","title":"Mandatory"},{"location":"na-bipartite/#standardised_2","text":"<p>Source, Target, Weight (here unitduration)</p>","title":"Standardised"},{"location":"na-bipartite/#2-workflow","text":"Workflow scopeWorkflow inputWorkflow output   <p>Undirected bipartite network analysis Undirected multigraph network analysis</p> <p>Workflow curated or created by: DH researcher</p> <p>DH related example? yes</p>   <p>Nodes (2 tables) and edges (1 table)</p>   <p>Computationally augmented nodes table User augmented nodes table User augmented edges table</p>","title":"2. Workflow"},{"location":"na-bipartite/#3-steps-considered","text":"","title":"3. Steps considered"},{"location":"na-bipartite/#step-1","text":"Step nameDescriptionInputsOutputsNotesQuestions   <p>Create graph object and computations</p>       Name Type     Edges Table   Nodes Table   Nodes Table   Col name for source nodes1 string   Col name for target nodes1 string   Col name for source nodes2 string   Col name for target nodes2 string   Edge attributes boolean         Name Type     Graph object    Graph properties Table(Number of nodes, number of edges, average degree)   Computationally augmented nodes Table(nodes degree, degree centrality, betweenness centrality, eigenvector centrality)   Isolated nodes array   Neighbours Table(Node Id, array of neighbours ID)   Shortest path Table(Node Id, array of nodes ID)   Edges duplicates Table(Source Id, Target ID, unitduration)   Connected Array[Boolean (isconnected?), if connected: number of connections]   Largest component graph object","title":"Step 1"},{"location":"na-bipartite/#step-2","text":"NameDescriptionInputsOutputsNotesQuestions   <p>Augmentation for nodes and edges table</p>    <p>Same as step 1, with additionally:</p>    Name Type     Modified nodes1 Table(nodeID, modified columns)   Modified nodes2 Table(nodeID, modified columns)   Modified edges Table(edgeID, modified columns)      <p>Same as step 1, with additionally:</p>    Name Type     User augmented nodes1 table Table   User augmented nodes2 table Table   User augmented edges table Table      <p>A strategy needs to be defined, so that from an UI perspective, users can re-run step 1 with data augmentation performed at step 1.</p>","title":"Step 2"},{"location":"na-bipartite/#step-3","text":"Step nameDescriptionInputsOutputsNotesQuestions   <p>Create multigraph object and computations</p>       Name Type     Edges Table         Name Type               <p>This step needs further clarification, I didn't understand if the graph is now bi-directed + multi</p>","title":"Step 3"},{"location":"na-bipartite/#4-implementation","text":"","title":"4. Implementation"},{"location":"na-directed-weighted/","text":"","title":"One mode graph, directed and weighted"},{"location":"na-directed-weighted/#1-data","text":"DescriptionNumber of filesFiles typeFiles aliasColumns   <p>Network data from journals in the field of psychiatry and allied fields</p>   <p>2</p>   <p>csv</p>   <p>Files alias is to simplify references to datasets for present doc</p> <ul> <li> <p>nodes</p> </li> <li> <p>edges</p> </li> </ul>","title":"1. Data"},{"location":"na-directed-weighted/#table-nodes","text":"","title":"Table \"nodes\""},{"location":"na-directed-weighted/#all","text":"Id   Label   City   CountryNetworkTime   PresentDayCountry   Latitude   Longitude   Country","title":"All"},{"location":"na-directed-weighted/#mandatory","text":"<p>Id</p>","title":"Mandatory"},{"location":"na-directed-weighted/#standardised","text":"<p>Id, Label</p>","title":"Standardised"},{"location":"na-directed-weighted/#table-edges","text":"","title":"Table \"edges\""},{"location":"na-directed-weighted/#all_1","text":"Source   Target   Weight","title":"All"},{"location":"na-directed-weighted/#mandatory_1","text":"<p>Source, Target</p>","title":"Mandatory"},{"location":"na-directed-weighted/#standardised_1","text":"<p>Source, Target, Weight</p>","title":"Standardised"},{"location":"na-directed-weighted/#2-workflow","text":"Workflow scopeExamples of research questionsWorkflow text summaryWorkflow inputWorkflow output   <p>Performing network analysis tasks on a one-mode network</p> <p>Workflow curated or created by: DH researcher</p> <p>DH related example? yes</p>   <p>What are the most important nodes (journals) in the network and how are they related to each other? What are the most likely channels of information in the network? Are there any bottlenecks? Are there any information hubs? What does the network structure look like? Are there any discernable clusters that correspond to journal characteristics, or are the links evenly distributed? Are there isolated node clusters that are not connected to the main network?  What does the dynamics of the network look like? Are there groups of nodes in which information flow forms disctinctly different patterns?</p>   <p>(from https://github.com/DHARPA-Project/NetworkXAnalysis) 1. Import data <ul> <li>Alternative data import</li> Extract nodes and edges from single file Preview nodes and edges list <li>Import data from edge list using pandas</li> Generate graph from edgelist <li>Add nodes and nodes attributes</li> </ul> 2. Get information about the generated graph and its properties <ul> <li>Test if nodes and edges correctly imported</li> <li>Get number of nodes and edges</li> <li>Get info about the augmented graph: average in degree, average out degree</li> </ul> 3. Make some basic calculations to obtain more graph properties <ul> <li>Density</li> <li>Find neighbors, successors and predecessors of individual nodes</li> <li>Find the shortest path between two nodes, display shortest path length</li> </ul> 4. Visualize the graph <ul> <li>Export graph to graphml file</li> <li>Import graphml with igraph</li> <li>Use Fruchterman-Reingold layout and draw with igraph</li> </ul> 5. Find largest component <ul> <li>Convert graph to undirected</li> <li>Print info about the graph in its undirected form: number of nodes, number of edges, average degree</li> <li>Find out if there is more than 1 component in graph</li> <li>Get list of connected components</li> <li>Get largest connected component and display its nodes</li> <li>Create subgraph (which will be returned as an indirect graph)</li> <li>Get info: number of nodes, number of edges, average degree</li> <li>Use largest component to create a directed subgraph</li> <li>Get directed subgraph info: number of nodes, number of edges, average in degree, average out degree</li> <li>Make some calculations for undirected graphs: diameter</li> <li>Find clusters that have strong connectivity</li> <li>Visualise clusters that have strong connectivity</li> <li>Alternate method: find and remove isolated nodes to create a subgraph, and then display number of nodes, edges, in degree, out degree, and density</li> </ul> 6. Make some centrality calculations <ul> <li>Calculate degrees, in degree, weighted degree, weighted in-degree, weighted out degree, and add as attribute, sort nodes by the metrics just calculated / display top n nodes according to these metrics</li> <li>Calculate, degree centrality, betweenness centrality, eigenvector centrality, add as attributes, sort, print top n nodes</li> </ul> 7. Community detection <ul> <li>export nx graph to graphml file</li> <li>create new infograph graph from file</li> <li>use Fruchterman-Reingold layout</li> <li>show list of unconnected nodes and remove them</li> <li>draw the graph with igraph</li> <li>export data to gefx and wisualise in Gephi</li> </ul> 8. Updating graph <ul> <li>Extract nodes and edges from additional file</li> <li>Display and sort new nodes</li> <li>Add new nodes to graph</li> <li>Display graph info: number of nodes, number of edges, average in degree, average out degree</li> <li>Create new graph from new edges and add them to old graph</li> <li>Display graph info: number of nodes, number of edges, average in degree, average out degree</li> <li>Visualise graph</li> <li>Get largest component from new graph and display info: number of nodes, edges, average in degree, average out degree</li> </ul></p>   <p>Nodes and edges tables</p>   <p>Computationally augmented nodes table User augmented nodes table User augmented edges table</p>","title":"2. Workflow"},{"location":"na-directed-weighted/#3-steps-considered","text":"","title":"3. Steps considered"},{"location":"na-directed-weighted/#step-1","text":"Step nameDescriptionInputsOutputsNotesQuestions   <p>Create graph object and computations</p>       Name Type     Edges Table   Nodes Table   Col name for source string   Col name for target string   Edge attributes boolean         Name Type     Graph object    Graph properties Table(Number of nodes, number of edges, average in-degree, average out-degree, network density)   Augmented nodes Table(nodes degree, in-degree, out-degree, weighted degree, weighted in-degree, weighted out-degree added, degree centrality, betweenness centrality, eigenvector centrality)   Isolated nodes array   Direct neighbours of nodes Table(Node id, array of outgoing connections ID)   Predecessors Table(Node Id, array of incoming connections ID)   All neighbours Table(Node Id, array of neighbours ID)   Weighted shortest path Table(Node Id, array of nodes ID)   Shortest path Table(Node Id, array of nodes ID)   Undirected graph computations Graph diameter   Communities Array of arrays      <p>If there\u2019s an error about edges or nodes computation as graph object, user needs to be made aware of it. UI should display the list of nodes and edges with attributes. For now everything is pre-computed (neighbours, shortest path), but a more efficient strategy may be to generate them on the fly, but the possibility for bi-directionality in such use case needs to be confirmed. To be verified/thought through: the largest component may be a distinct step, or the same one with different nodes and edges, since it's possible that it would be the same module/viz ran again with only the nodes and edges of largest component. To be verified/thought through: the conversion to undirected may call to another module that would be for directed graph: I don't think that it will be possible to recursively convert to directed/undirected within same module</p>   <p>Are the undirected computations presented in this notebook all relevant for a directed graph? Is the removal of isolated nodes only relevant for viz display or would users need to remove them in graph object? I read (externally, in a book) that, for example, the density measure need to be considered carefully in some cases, especially for valued graphs, is this relevant here, and where would this info be displayed in the requirements gathering (this will brought up as meeting item as this is more of a general discussion) Part about convert graph to undirected to be clarified (is there a reason subgraphs are computed in this section?)</p>","title":"Step 1"},{"location":"na-directed-weighted/#step-2","text":"NameDescriptionInputsOutputsNotesQuestions   <p>Augmentation for nodes and edges table</p>    <p>Same as step 1, with additionally:</p>    Name Type     Modified nodes Table(nodeID, modified columns)   Modified edges Table(edgeID, modified columns)      <p>Same as step 1, with additionally:</p>    Name Type     User augmented nodes table Table   User augmented edges table Table      <p>A strategy needs to be defined, so that from an UI perspective, users can re-run step 1 with data augmentation performed at step 1.</p>","title":"Step 2"},{"location":"na-directed-weighted/#4-implementation","text":"","title":"4. Implementation"}]}